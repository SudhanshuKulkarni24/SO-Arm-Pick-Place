{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37e5516d",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508deca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path(os.getcwd()).parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7579b67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import imageio\n",
    "from IPython.display import Video, display, HTML\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback, EvalCallback\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "\n",
    "from src.envs.pick_place import PickPlaceEnv\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972d1520",
   "metadata": {},
   "source": [
    "## 2. Test Environment (Sanity Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5670409f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create environment and verify it works\n",
    "env = PickPlaceEnv(\n",
    "    render_mode=\"rgb_array\",\n",
    "    max_episode_steps=400,\n",
    "    place_target=(0.35, 0.10),\n",
    "    randomize_cube=False,\n",
    "    randomize_target=False,\n",
    ")\n",
    "\n",
    "obs, info = env.reset()\n",
    "print(f\"Observation shape: {obs.shape}\")\n",
    "print(f\"Action space: {env.action_space}\")\n",
    "print(f\"Cube position: {info['cube_pos']}\")\n",
    "print(f\"Target position: {info['place_target']}\")\n",
    "\n",
    "# Take a random action\n",
    "action = env.action_space.sample()\n",
    "obs, reward, terminated, truncated, info = env.step(action)\n",
    "print(f\"\\nRandom action reward: {reward:.3f}\")\n",
    "\n",
    "# Render a frame\n",
    "frame = env.render()\n",
    "print(f\"Frame shape: {frame.shape}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246eedac",
   "metadata": {},
   "source": [
    "## 3. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9506e7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "CONFIG = {\n",
    "    # Training\n",
    "    \"total_timesteps\": 1_000_000,  # Reduce for quick test, increase to 2M for full training\n",
    "    \"eval_freq\": 10_000,\n",
    "    \"save_freq\": 50_000,\n",
    "    \"seed\": 42,\n",
    "    \n",
    "    # SAC hyperparameters\n",
    "    \"learning_rate\": 3e-4,\n",
    "    \"buffer_size\": 100_000,\n",
    "    \"learning_starts\": 1_000,\n",
    "    \"batch_size\": 256,\n",
    "    \"tau\": 0.005,\n",
    "    \"gamma\": 0.99,\n",
    "    \"train_freq\": 1,\n",
    "    \"gradient_steps\": 1,\n",
    "    \n",
    "    # Environment\n",
    "    \"max_episode_steps\": 400,\n",
    "    \"action_scale\": 0.02,\n",
    "    \"lift_height\": 0.08,\n",
    "    \"reward_version\": \"v21\",  # v21 has improved grasp incentives (RECOMMENDED)\n",
    "    \"curriculum_stage\": 3,\n",
    "    \"place_target\": (0.35, 0.10),\n",
    "}\n",
    "\n",
    "# Output directory\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = project_root / \"runs\" / \"pick_place_notebook\" / timestamp\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66051146",
   "metadata": {},
   "source": [
    "## 4. Create Training Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33effe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env():\n",
    "    return PickPlaceEnv(\n",
    "        render_mode=None,\n",
    "        max_episode_steps=CONFIG[\"max_episode_steps\"],\n",
    "        action_scale=CONFIG[\"action_scale\"],\n",
    "        lift_height=CONFIG[\"lift_height\"],\n",
    "        reward_version=CONFIG[\"reward_version\"],\n",
    "        curriculum_stage=CONFIG[\"curriculum_stage\"],\n",
    "        place_target=CONFIG[\"place_target\"],\n",
    "        randomize_cube=True,\n",
    "        randomize_target=True,\n",
    "    )\n",
    "\n",
    "# Training environment with normalization\n",
    "train_env = DummyVecEnv([make_env])\n",
    "train_env = VecNormalize(train_env, norm_obs=True, norm_reward=True)\n",
    "\n",
    "# Evaluation environment\n",
    "eval_env = DummyVecEnv([make_env])\n",
    "eval_env = VecNormalize(eval_env, norm_obs=True, norm_reward=False, training=False)\n",
    "\n",
    "print(\"Environments created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1768b0f0",
   "metadata": {},
   "source": [
    "## 5. Create SAC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4d77f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = SAC(\n",
    "    \"MlpPolicy\",\n",
    "    train_env,\n",
    "    learning_rate=CONFIG[\"learning_rate\"],\n",
    "    buffer_size=CONFIG[\"buffer_size\"],\n",
    "    learning_starts=CONFIG[\"learning_starts\"],\n",
    "    batch_size=CONFIG[\"batch_size\"],\n",
    "    tau=CONFIG[\"tau\"],\n",
    "    gamma=CONFIG[\"gamma\"],\n",
    "    train_freq=CONFIG[\"train_freq\"],\n",
    "    gradient_steps=CONFIG[\"gradient_steps\"],\n",
    "    verbose=1,\n",
    "    seed=CONFIG[\"seed\"],\n",
    "    device=device,\n",
    "    tensorboard_log=str(output_dir / \"tensorboard\"),\n",
    ")\n",
    "\n",
    "print(f\"Model created on device: {device}\")\n",
    "print(f\"Policy: {model.policy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c0cf80",
   "metadata": {},
   "source": [
    "## 6. Setup Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452b6830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint callback - save model periodically\n",
    "checkpoint_callback = CheckpointCallback(\n",
    "    save_freq=CONFIG[\"save_freq\"],\n",
    "    save_path=str(output_dir / \"checkpoints\"),\n",
    "    name_prefix=\"sac_pick_place\",\n",
    ")\n",
    "\n",
    "# Evaluation callback - evaluate and save best model\n",
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    best_model_save_path=str(output_dir / \"best_model\"),\n",
    "    log_path=str(output_dir / \"eval_logs\"),\n",
    "    eval_freq=CONFIG[\"eval_freq\"],\n",
    "    deterministic=True,\n",
    "    render=False,\n",
    ")\n",
    "\n",
    "print(\"Callbacks configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e923a90b",
   "metadata": {},
   "source": [
    "## 7. Train the Agent\n",
    "\n",
    "⚠️ **Note**: Training will take some time depending on `total_timesteps`:\n",
    "- 100K steps: ~5-10 minutes\n",
    "- 500K steps: ~30-60 minutes  \n",
    "- 2M steps: ~2-4 hours (GPU) / ~8-12 hours (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bab420",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Starting training for {CONFIG['total_timesteps']:,} timesteps...\")\n",
    "print(f\"Checkpoints will be saved to: {output_dir / 'checkpoints'}\")\n",
    "print(f\"Best model will be saved to: {output_dir / 'best_model'}\")\n",
    "print()\n",
    "\n",
    "model.learn(\n",
    "    total_timesteps=CONFIG[\"total_timesteps\"],\n",
    "    callback=[checkpoint_callback, eval_callback],\n",
    "    progress_bar=True,\n",
    ")\n",
    "\n",
    "# Save final model and normalization stats\n",
    "model.save(output_dir / \"final_model\")\n",
    "train_env.save(output_dir / \"vec_normalize.pkl\")\n",
    "\n",
    "print(f\"\\n✅ Training complete!\")\n",
    "print(f\"Final model saved to: {output_dir / 'final_model.zip'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10dcadb",
   "metadata": {},
   "source": [
    "## 8. Load Best Model for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9369ddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "best_model_path = output_dir / \"best_model\" / \"best_model.zip\"\n",
    "if best_model_path.exists():\n",
    "    eval_model = SAC.load(best_model_path, device=device)\n",
    "    print(f\"Loaded best model from: {best_model_path}\")\n",
    "else:\n",
    "    eval_model = model\n",
    "    print(\"Using final model for evaluation\")\n",
    "\n",
    "# Load normalization stats\n",
    "vec_normalize_path = output_dir / \"vec_normalize.pkl\"\n",
    "if vec_normalize_path.exists():\n",
    "    print(f\"Normalization stats available at: {vec_normalize_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08049950",
   "metadata": {},
   "source": [
    "## 9. Evaluate and Record Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a523b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_record(model, num_episodes=3):\n",
    "    \"\"\"Evaluate model and record videos.\"\"\"\n",
    "    \n",
    "    # Create environment with rendering\n",
    "    env = PickPlaceEnv(\n",
    "        render_mode=\"rgb_array\",\n",
    "        max_episode_steps=CONFIG[\"max_episode_steps\"],\n",
    "        place_target=CONFIG[\"place_target\"],\n",
    "        randomize_cube=False,\n",
    "        randomize_target=False,\n",
    "    )\n",
    "    \n",
    "    # Load normalization if available\n",
    "    vec_env = DummyVecEnv([lambda: env])\n",
    "    if vec_normalize_path.exists():\n",
    "        vec_env = VecNormalize.load(vec_normalize_path, vec_env)\n",
    "        vec_env.training = False\n",
    "        vec_env.norm_reward = False\n",
    "    \n",
    "    all_frames = []\n",
    "    results = []\n",
    "    \n",
    "    for ep in range(num_episodes):\n",
    "        obs = vec_env.reset()\n",
    "        frames = []\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        step = 0\n",
    "        \n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, info = vec_env.step(action)\n",
    "            total_reward += reward[0]\n",
    "            step += 1\n",
    "            \n",
    "            # Render frame\n",
    "            frame = env.render()\n",
    "            if frame is not None:\n",
    "                frames.append(frame)\n",
    "        \n",
    "        success = info[0].get(\"is_success\", False)\n",
    "        results.append({\"episode\": ep + 1, \"reward\": total_reward, \"steps\": step, \"success\": success})\n",
    "        print(f\"Episode {ep + 1}: Reward={total_reward:.2f}, Steps={step}, Success={success}\")\n",
    "        \n",
    "        all_frames.extend(frames)\n",
    "    \n",
    "    env.close()\n",
    "    \n",
    "    return all_frames, results\n",
    "\n",
    "print(\"Recording evaluation episodes...\")\n",
    "frames, results = evaluate_and_record(eval_model, num_episodes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e6a56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EVALUATION SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "for r in results:\n",
    "    status = \"✅\" if r[\"success\"] else \"❌\"\n",
    "    print(f\"Episode {r['episode']}: {status} Reward={r['reward']:.2f}, Steps={r['steps']}\")\n",
    "\n",
    "success_rate = sum(1 for r in results if r[\"success\"]) / len(results) * 100\n",
    "avg_reward = np.mean([r[\"reward\"] for r in results])\n",
    "print(f\"\\nSuccess Rate: {success_rate:.1f}%\")\n",
    "print(f\"Average Reward: {avg_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676d6208",
   "metadata": {},
   "source": [
    "## 10. Save and Display Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd14045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save video\n",
    "video_path = output_dir / \"evaluation_video.mp4\"\n",
    "if frames:\n",
    "    imageio.mimsave(str(video_path), frames, fps=30)\n",
    "    print(f\"Video saved to: {video_path}\")\n",
    "    print(f\"Total frames: {len(frames)}\")\n",
    "else:\n",
    "    print(\"No frames recorded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc1e32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display video in notebook\n",
    "if video_path.exists():\n",
    "    display(Video(str(video_path), embed=True, width=640))\n",
    "else:\n",
    "    print(\"Video file not found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da0cd9d",
   "metadata": {},
   "source": [
    "## 11. Test with Custom Target (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df29921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_custom_target(model, target_x=0.30, target_y=0.15):\n",
    "    \"\"\"Test the model with a custom target location.\"\"\"\n",
    "    \n",
    "    env = PickPlaceEnv(\n",
    "        render_mode=\"rgb_array\",\n",
    "        max_episode_steps=400,\n",
    "        place_target=(target_x, target_y),\n",
    "        randomize_cube=False,\n",
    "        randomize_target=False,\n",
    "    )\n",
    "    \n",
    "    vec_env = DummyVecEnv([lambda: env])\n",
    "    if vec_normalize_path.exists():\n",
    "        vec_env = VecNormalize.load(vec_normalize_path, vec_env)\n",
    "        vec_env.training = False\n",
    "        vec_env.norm_reward = False\n",
    "    \n",
    "    obs = vec_env.reset()\n",
    "    frames = []\n",
    "    done = False\n",
    "    \n",
    "    print(f\"Testing with target at ({target_x}, {target_y})...\")\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = vec_env.step(action)\n",
    "        frame = env.render()\n",
    "        if frame is not None:\n",
    "            frames.append(frame)\n",
    "    \n",
    "    success = info[0].get(\"is_success\", False)\n",
    "    print(f\"Result: {'SUCCESS ✅' if success else 'FAILED ❌'}\")\n",
    "    \n",
    "    # Save video\n",
    "    custom_video_path = output_dir / f\"custom_target_{target_x}_{target_y}.mp4\"\n",
    "    imageio.mimsave(str(custom_video_path), frames, fps=30)\n",
    "    print(f\"Video saved to: {custom_video_path}\")\n",
    "    \n",
    "    env.close()\n",
    "    return custom_video_path\n",
    "\n",
    "# Test with a different target\n",
    "custom_video = test_custom_target(eval_model, target_x=0.30, target_y=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c7f5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display custom target video\n",
    "if custom_video.exists():\n",
    "    display(Video(str(custom_video), embed=True, width=640))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b6ff0a",
   "metadata": {},
   "source": [
    "## 12. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73442822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close environments\n",
    "train_env.close()\n",
    "eval_env.close()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nAll outputs saved to: {output_dir}\")\n",
    "print(f\"\\nFiles:\")\n",
    "for f in output_dir.rglob(\"*\"):\n",
    "    if f.is_file():\n",
    "        print(f\"  - {f.relative_to(output_dir)}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
